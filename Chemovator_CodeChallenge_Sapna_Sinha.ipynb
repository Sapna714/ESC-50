{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chemovator_CodeChallenge_Sapna Sinha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWiCksV69QgJ8YO5Qg4Tpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sapna714/ESC-50/blob/master/Chemovator_CodeChallenge_Sapna_Sinha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sd8z9X6s6ir"
      },
      "source": [
        "\n",
        "\n",
        "# Chemovator Code Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6XQ3Aawijl"
      },
      "source": [
        "* Information Retrieval using Semantic Search\n",
        "* Input Query provided by a user ---> Intelligent answer provided by the model from within documents "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8OkTdKotCYv"
      },
      "source": [
        "Given a set of documents, Task is to review semantic search. \n",
        "Reference : [Amazon Kendra](https://aws.amazon.com/kendra/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfimurNvwM_m",
        "outputId": "035c8eb7-a208-48cb-fafc-7bf2fb365420"
      },
      "source": [
        "!pip install tika"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika) (50.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (3.0.4)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp36-none-any.whl size=32884 sha256=0e13202acb93b7942b99a676dda8e9b1a09043beb89fe178c2c989611e736b32\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVpewRaawLsJ"
      },
      "source": [
        "from tika import parser # pip install tika\n",
        "\n",
        "raw = parser.from_file('/content/RheovisFRCAnimalTesting.pdf')\n",
        "print(raw['content'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXUf4zyQw5FK",
        "outputId": "a1c62300-2662-4090-e464-164462d9b281"
      },
      "source": [
        "type(raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Oy0qaBqNsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ab60f02-dd1e-47f8-901f-e5441b4db8b1"
      },
      "source": [
        "#Installing required packages\n",
        "#Ref: https://textract.readthedocs.io/en/stable/installation.html\n",
        "!apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr \\\n",
        "flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "!pip install textract\n",
        "\n",
        "#Ref: https://pypi.org/project/sentence-transformers/\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "libxml2-dev is already the newest version (2.9.4+dfsg1-6.1ubuntu1.3).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libid3tag0 libijs-0.35 libjbig2dec0\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 poppler-data swig3.0 tesseract-ocr-eng\n",
            "  tesseract-ocr-osd\n",
            "Suggested packages:\n",
            "  fonts-noto ghostscript-x lame-doc file libsox-fmt-all fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum swig-doc swig-examples\n",
            "  swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  antiword flac fonts-droid-fallback fonts-noto-mono ghostscript gsfonts lame\n",
            "  libcupsfilters1 libcupsimage2 libgs9 libgs9-common libid3tag0 libijs-0.35\n",
            "  libjbig2dec0 libmad0 libmagic-mgc libmagic1 libopencore-amrnb0\n",
            "  libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox-fmt-mp3 libsox3\n",
            "  libxslt1-dev poppler-data poppler-utils pstotext sox swig swig3.0\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd unrtf\n",
            "0 upgraded, 34 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 21.8 MB of archives.\n",
            "After this operation, 83.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 antiword amd64 0.37-11build1 [128 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 flac amd64 1.3.2-1 [144 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.13 [5,092 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.13 [2,263 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.13 [51.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/universe amd64 lame amd64 3.100-2 [47.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libid3tag0 amd64 0.15.1b-13 [31.2 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libmad0 amd64 0.15.1b-9ubuntu18.04.1 [64.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2-3ubuntu0.18.04.1 [15.9 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxslt1-dev amd64 1.1.29-5ubuntu0.2 [407 kB]\n",
            "Ign:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.10\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pstotext amd64 1.9-6build1 [32.4 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Err:26 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.10\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 unrtf amd64 0.21.9-clean-3 [43.3 kB]\n",
            "Fetched 21.7 MB in 2s (12.6 MB/s)\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_0.62.0-2ubuntu2.10_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting textract\n",
            "  Downloading https://files.pythonhosted.org/packages/32/31/ef9451e6e48a1a57e337c5f20d4ef58c1a13d91560d2574c738b1320bb8d/textract-1.6.3-py3-none-any.whl\n",
            "Collecting SpeechRecognition==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 134kB/s \n",
            "\u001b[?25hCollecting argcomplete==1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/82/f44c9661e479207348a979b1f6f063625d11dc4ca6256af053719bbb0124/argcomplete-1.10.0-py2.py3-none-any.whl\n",
            "Collecting python-pptx==0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/86/eb979f7b0333ec769041aae36df8b9f1bd8bea5bbad44620663890dce561/python-pptx-0.6.18.tar.gz (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 45.9MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n",
            "\u001b[?25hCollecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting xlrd==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 50.8MB/s \n",
            "\u001b[?25hCollecting extract-msg==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/90/84485a914ed90adb5e87df17e626be04162fbba146dfecf34643659a4633/extract_msg-0.23.1-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting docx2txt==0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz\n",
            "Collecting EbookLib==0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/38/7d6ab2e569a9165249619d73b7bc6be0e713a899a3bc2513814b6598a84c/EbookLib-0.17.1.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 44.3MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20181108\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/6e8746e6965d1a7ea8e97253e3d79e625da5547e8f376f88de5d024bacb9/pdfminer.six-20181108-py2.py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (7.0.0)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/41/bf1aae04932d1eaffee1fc5f8b38ca47bbbf07d765129539bc4bcce1ce0c/XlsxWriter-1.3.7-py2.py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 33.8MB/s \n",
            "\u001b[?25hCollecting soupsieve>=1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n",
            "Collecting olefile==0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal==1.5.1 in /usr/local/lib/python3.6/dist-packages (from extract-msg==0.23.1->textract) (1.5.1)\n",
            "Collecting imapclient==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/39/e1c2c2c6e2356ab6ea81fcfc0a74b044b311d6a91a45300811d9a6077ef7/IMAPClient-2.1.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/6f/7e38d7c97fbbc3987539c804282c33f56b6b07381bf2390deead696440c5/pycryptodome-3.9.9-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six==20181108->textract) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2018.9)\n",
            "Building wheels for collected packages: python-pptx, docx2txt, EbookLib, olefile\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.18-cp36-none-any.whl size=275707 sha256=afec3b40bc7725a754a8b0d8ef428ac66d151f2432e2f1ac0c64428c3075465b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/1f/2c/29acca422b420a0b5210bd2cd7e9669804520d602d2462f20b\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-cp36-none-any.whl size=3965 sha256=82254276ee583febfbb57e352b50348a58696d8674b359a4e983f360ef548b12\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/26/a051209bbb77fc6bcfae2bb7e01fa0ff941b82292ab084d596\n",
            "  Building wheel for EbookLib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for EbookLib: filename=EbookLib-0.17.1-cp36-none-any.whl size=38163 sha256=ac81db349a175f79c39477156e03c9070cd4cf4916b62ffc4c7edd91316bb253\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/11/01/951369cbbf8f96878786a1f4da68bd7ac19a5d945b38e03d54\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35415 sha256=191c90ed08825b1ffbd48caee405a6b207d9259c5abb3a75df1dbb1c4c884420\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "Successfully built python-pptx docx2txt EbookLib olefile\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: SpeechRecognition, argcomplete, XlsxWriter, python-pptx, soupsieve, beautifulsoup4, six, xlrd, olefile, imapclient, extract-msg, docx2txt, EbookLib, pycryptodome, pdfminer.six, textract\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "Successfully installed EbookLib-0.17.1 SpeechRecognition-3.8.1 XlsxWriter-1.3.7 argcomplete-1.10.0 beautifulsoup4-4.8.0 docx2txt-0.8 extract-msg-0.23.1 imapclient-2.1.0 olefile-0.46 pdfminer.six-20181108 pycryptodome-3.9.9 python-pptx-0.6.18 six-1.12.0 soupsieve-2.0.1 textract-1.6.3 xlrd-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hCollecting transformers<3.6.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence-transformers) (50.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101036 sha256=35af98e3e4af8ba47ca34ff3526632fc84f46bc3f0a6342fb898d57ca5c8c56e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=26b2b00c2da08d9d065533fdb94ce4dadb66816c36a9bccc3aa3fde01439ece3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.9 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m2PjfvxJeVS",
        "outputId": "3d95fe73-2441-46ef-f9ba-e059ddd27123"
      },
      "source": [
        "#Importing required libraries\n",
        "import os\n",
        "#import textract\n",
        "import nltk\n",
        "import re\n",
        "import scipy\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcGrHcglFwtH"
      },
      "source": [
        "#Reading all the PDF files\n",
        "\n",
        "files_path = ['/content/RheovisFRC/RheovisFRCAnimalTesting.pdf',\n",
        "               '/content/RheovisFRC/RheovisFRCNanoStatement.pdf',\n",
        "               '/content/RheovisFRC/RheovisFRCProductSpecification.pdf',\n",
        "               '/content/RheovisFRC/RheovisFRCSVHC.pdf',\n",
        "               '/content/RheovisFRC/RheovisFRCTechnicalInformation.pdf',\n",
        "              \"/content/SokalanCP5/SokalanCP5AnimalTesting.pdf\",\"/content/SokalanCP5/SokalanCP5FoodEU.pdf\",\"/content/SokalanCP5/SokalanCP5NanoStatementFR.pdf\",\"/content/SokalanCP5/SokalanCP5ProductSpecification.pdf\",\"/content/SokalanCP5/SokalanCP5REACHpolymers.pdf\",\n",
        "              \"/content/SokalanCP5/SokalanCP5SVHC.pdf\",\"/content/SokalanCP5/SokalanCP5TechnicalInformation.pdf\",\n",
        "              \"/content/TexaponN70/TexaponN70SVHC.pdf\",\"/content/TexaponN70/TexaponN70TechnicalInformation.pdf\"\n",
        "              ]\n",
        "\n",
        "# Excluding not .pdf files\n",
        "files_path = [pdf for pdf in files_path if '.pdf' in pdf]\n",
        "\n",
        "pdfs = []\n",
        "for file in files_path:\n",
        "    text = textract.process(file,\n",
        "                            method='tesseract',\n",
        "                            language='eng')\n",
        "\n",
        "    pdfs += [text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocgfibhbHU1x",
        "outputId": "96519eb8-6946-4367-f594-1cfd4b6373b1"
      },
      "source": [
        "pdfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Ol- BASF\\n\\nWe create chemistry\\n\\nStatement\\n\\nAnimal Testing\\n\\n \\n\\ni Valid since 01/2020\\nRheovis\\xc2\\xae FRC Revision 3.0\\nPRD 30478270 WE-no.: 6808\\nPage 1 of 1\\n\\n \\n\\n@\\xc2\\xae = Registered trademark of BASF in many countries \\xe2\\x80\\x94_\\xe2\\x84\\xa2 = Trademark of BASF Care Chemicals\\n\\nDue to legal requirements and regulations of the European Union, BASF SE is obliged to perform animal\\nstudies on chemical substances. Within this document animals are regarded as vertebrates. The objective of\\nthese studies is to minimize the risk to humans, animals and the environment. Animal studies are centrally\\nmonitored by BASF SE to guarantee that the studies commissioned by BASF worldwide are carried out in\\naccordance with the same ethical aspects and animal welfare considerations as those performed within BASF.\\n\\nBASF\\xe2\\x80\\x99s company policy is to eliminate all unnecessary animal testing and to support the development of\\nalternative test methods that involve in vitro testing or that require the minimum possible number of animals.\\nHowever, alternative test methods are not available for all toxicological end points, and the validation of such\\ntest methods again requires the use of animals.\\n\\nThe product is used in chemical and technical applications\\n\\nThe product has not been tested on animals by BASF. The assessment has been derived from the components\\nor products of similar chemical composition.\\n\\nThis document and any information provided herein is for your guidance only. All information is given in good faith and is based on sources\\nbelieved to be reliable and accurate at the date of publication of this document. This document shall be valid until superseded by a later\\nversion. BASF MAKES NO WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, BY FACT OR LAW, INCLUDING\\nWARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE\\n\\nThis is a computer generated document. It is valid without signature\\n\\x0c',\n",
              " b'O= BASF\\n\\nWe create chemistry\\n\\nProduct specification\\n\\n \\n\\nRheovis\\xc2\\xae FRC\\n\\n= registered Trademark of BASF\\n\\nTest property\\n\\nValid since: 16.09.2015\\nRevision: 1\\nWF-No.: 7005\\nPRD 30478270 page:\\n\\xe2\\x84\\xa2 = Trademark of BASF Care Chemicals\\nin many countries\\nChemical description: catiol\\ntechr\\nPhysical form: white\\nSpecifi\\xe2\\x82\\xacasomethod\\nProduciwhiteut 6fj white visual\\nAppear@ispatsion visual\\nCharactligisiat (*) visual\\n\\nViscosity200 - 3500 mPa:s\\n\\nConcensaitbnXag @ontent)\\n\\nBrookfield RVT, 1,0%\\nwater, 25 \\xc2\\xb0C, spindle\\n(stir well for 20 min, le\\nfor additional 35 min,\\nDIN EN ISO 3251, (5\\nshare insoluble in ace\\n(*) Test verified on rar\\n\\nThe aforementioned di\\nThe data are controllec\\nWARRANTY OF ANY\\nMERCHANTABILITY\\n\\nThis is a computer gen\\n\\x0c']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1RRdVzlBdi6"
      },
      "source": [
        "#Text Preprocessing\n",
        "import re\n",
        "#Converting to string\n",
        "str1 = ''.join(str(e) for e in raw['content'])\n",
        "\n",
        "#Converting to lower case\n",
        "str1 = str1.lower()\n",
        "\n",
        "#Removing special characters\n",
        "final = [re.sub(r\"\\W+|_\", ' ', k) for k in str1.split(\"\\n\")]\n",
        "\n",
        "#Removing empty strings\n",
        "sentences = list(filter(None, final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVs3aVrfNJNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e61f95-cb04-4146-97cb-83495134b16c"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['statement',\n",
              " 'animal testing',\n",
              " 'this document and any information provided herein is for your guidance only all information is given in good faith and is based on sources ',\n",
              " 'believed to be reliable and accurate at the date of publication of this document this document shall be valid until superseded by a later ',\n",
              " 'version basf makes no warranty of any kind either express or implied by fact or law including ',\n",
              " 'warranties of merchantability or fitness for a particular purpose',\n",
              " 'this is a computer generated document it is valid without signature',\n",
              " 'due to legal requirements and regulations of the european union basf se is obliged to perform animal',\n",
              " 'studies on chemical substances within this document animals are regarded as vertebrates the objective of',\n",
              " 'these studies is to minimize the risk to humans animals and the environment animal studies are centrally',\n",
              " 'monitored by basf se to guarantee that the studies commissioned by basf worldwide are carried out in',\n",
              " 'accordance with the same ethical aspects and animal welfare considerations as those performed within basf ',\n",
              " 'basf s company policy is to eliminate all unnecessary animal testing and to support the development of',\n",
              " 'alternative test methods that involve in vitro testing or that require the minimum possible number of animals ',\n",
              " 'however alternative test methods are not available for all toxicological end points and the validation of such',\n",
              " 'test methods again requires the use of animals ',\n",
              " 'the product is used in chemical and technical applications ',\n",
              " 'the product has not been tested on animals by basf the assessment has been derived from the components',\n",
              " 'or products of similar chemical composition ',\n",
              " 'rheovis frc',\n",
              " 'prd 30478270',\n",
              " ' valid since 01 2020',\n",
              " ' revision 3 0 ',\n",
              " ' wf no 6808 ',\n",
              " ' page 1 of 1',\n",
              " ' care chemicals registered trademark of basf in many countries trademark of basf ',\n",
              " 'issued for pavan kumar ravinutala basf com on 03 08 2020']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JURex2p3OaWR",
        "outputId": "f6ccccd1-3606-481b-ec5a-7d406665f5f7"
      },
      "source": [
        "#Reference :https://www.sbert.net/, https://github.com/evergreenllc2020/ , https://www.aclweb.org/anthology/D19-1410.pdf\n",
        "model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
        "sentence_embeddings = model.encode(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.31G/1.31G [00:48<00:00, 27.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8c6dEatIrBn"
      },
      "source": [
        "#Forming test input queries\n",
        "query = \"Did they perform animal testing? on the product?\"\n",
        "#query = \"When was latest animal test conducted for sokalan?\"\n",
        "#query = \"What does data say about animals?\"\n",
        "#query = \"What is the appearance of texapon?\"\n",
        "#query = \" what is the shelf life of sokalan?\"\n",
        "#query = \"what is the physical form of rheovis?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wNV0CEDCtZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f598b0a2-818e-480a-e617-8cd9861deed5"
      },
      "source": [
        "queries = [query]\n",
        "query_embeddings = model.encode(queries)\n",
        "\n",
        "#5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "number_top_matches = 5 \n",
        "\n",
        "print(\"Semantic Search Results\")\n",
        "\n",
        "for query, query_embedding in zip(queries, query_embeddings):\n",
        "    distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, \"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "    \n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "    \n",
        "    values = set()\n",
        "    for idx, distance in results[0:number_top_matches]:\n",
        "      if distance not in values:\n",
        "        print(sentences[idx].strip(), \"(Cosine Score: %.4f)\" % (1-distance))\n",
        "        values.add(distance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Semantic Search Results\n",
            "Query: Did they perform animal testing? on the product?\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "animal testing (Cosine Score: 0.7900)\n",
            "test methods again requires the use of animals (Cosine Score: 0.7413)\n",
            "alternative test methods that involve in vitro testing or that require the minimum possible number of animals (Cosine Score: 0.6750)\n",
            "the product has not been tested on animals by basf the assessment has been derived from the components (Cosine Score: 0.6233)\n",
            "these studies is to minimize the risk to humans animals and the environment animal studies are centrally (Cosine Score: 0.5693)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVNoEHr3tql7"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRsZv8XctBq0"
      },
      "source": [
        "Semantic Search Results\n",
        "\n",
        "======================\n",
        "\n",
        "\n",
        "Query:  what is the shelf life of sokalan?\n",
        "\n",
        "Top 5 most similar sentences in corpus:\n",
        "\n",
        "shelf life sokalan xc2 xae cp 5 has a shelf life of at least 24 months in its original packaging (Cosine Score: 0.5398)\n",
        "\n",
        "shelf life (Cosine Score: 0.4536)\n",
        "\n",
        "for sokalan xc2 xae cp 5 (Cosine Score: 0.4448)\n",
        "\n",
        "sokalan xc2 xae cp 5 (Cosine Score: 0.4334)\n",
        "\n",
        "scenario provided in the annex of the sds (Cosine Score: 0.4142)\n",
        "\n",
        "======================\n",
        "\n",
        "Query: What does data say about animals?\n",
        "\n",
        "Top 5 most similar sentences in corpus:\n",
        "\n",
        "animal testing (Cosine Score: 0.7604)\n",
        "\n",
        "test methods again requires the use of animals (Cosine Score: 0.7446)\n",
        "\n",
        "studies on chemical substances within this document animals are regarded as vertebrates the objective of (Cosine Score: 0.7113)\n",
        "\n",
        "alternative test methods that involve in vitro testing or that require the minimum possible number of animals (Cosine Score: 0.5833)\n",
        "\n",
        "due to legal requirements and regulations of the european union basf se is obliged to perform animal (Cosine Score: 0.5065)\n",
        "\n",
        "======================\n",
        "\n",
        "\n",
        "Query: what is the physical form of rheovis?\n",
        "\n",
        "Top 5 most similar sentences in corpus:\n",
        "\n",
        "physical form aque (Cosine Score: 0.5074)\n",
        "\n",
        "physical form white (Cosine Score: 0.4334)\n",
        "\n",
        "physical form dispersion (Cosine Score: 0.4303)\n",
        "\n",
        "sodium laureth sulfate 68 73 (Cosine Score: 0.4196)\n",
        "\n",
        "if samples of rheovis xc2 xae frc are required for analytical testing they must be (Cosine Score: 0.4077)\n",
        "\n",
        "\n",
        "\n",
        "======================\n",
        "\n",
        "\n",
        "Query: When was latest animal test conducted for sokalan?\n",
        "\n",
        "Top 5 most similar sentences in corpus:\n",
        "\n",
        "latest tests on animals for this product were conducted by basf in 1985 (Cosine Score: 0.6070)\n",
        "\n",
        "animal testing (Cosine Score: 0.4989)\n",
        "\n",
        "test methods again requires the use of animals (Cosine Score: 0.4711)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZiYW22rDiz"
      },
      "source": [
        "**Scope of enhancement**\n",
        "\n",
        "*In view of usecase*\n",
        "\n",
        "\n",
        "*   Streamline Document structure and parsing\n",
        "*   Text preprocessing scalability\n",
        "\n",
        "*In view of techniques used*\n",
        "\n",
        "* Sentence Bert was used for this task (Ref: https://www.aclweb.org/anthology/D19-1410.pdf, https://www.sbert.net/docs/quickstart.html)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qaf0HUVsKey"
      },
      "source": [
        "All the works referenced have been cited. The implementation on the given dataset and the conclusions drawn belong to the owner of the notebook. "
      ]
    }
  ]
}